{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9778dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from pandas import read_csv\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from matplotlib.pyplot import savefig\n",
    "test_size = 0.1\n",
    "filename = 'D:\\Jupyter notebook\\é”°åŸºé™¤é‡é‡‘å±\\ç‹¬çƒ­ç¼–ç åˆ é™¤æ‰€æœ‰ç©ºç¼ºå€¼.csv'\n",
    "data0 = read_csv(filename)\n",
    "\n",
    "# å‡è®¾ 'data0' æ˜¯ä½ çš„ DataFrame\n",
    "X = data0.drop(columns=['Adsorption capacity'])  # é€‰æ‹©é™¤äº†æœ€åä¸€åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—ä½œä¸ºç‰¹å¾\n",
    "y = data0['Adsorption capacity']   # é€‰æ‹©æœ€åä¸€åˆ—ä½œä¸ºç›®æ ‡å˜é‡\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=6)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "param_grid = {'learning_rate': [0.1,0.15,0.35],\n",
    "              'max_depth': [3],\n",
    "              'min_child_weight': [3,4,5],\n",
    "              'colsample_bytree': [0.8],\n",
    "              'gamma': [0, 0.1, 0.2, 0.3],\n",
    "              'reg_alpha': [0,0.1,0.2,0.3],\n",
    "              'reg_lambda': [1,3,5]\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "param_grid = param_grid\n",
    "n_splits = 10\n",
    "seed = 10\n",
    "k_fold = KFold(n_splits=n_splits, random_state=seed, shuffle=True)\n",
    "xgb_regressor = xgb.sklearn.XGBRegressor()\n",
    "model = GridSearchCV(estimator=xgb_regressor, scoring='neg_root_mean_squared_error', param_grid=param_grid, cv=k_fold,\n",
    "                     verbose=3, n_jobs=-1, return_train_score=True)\n",
    "model.fit(X_train_std, y_train)\n",
    "print(model.cv_results_)\n",
    "df_result = pd.DataFrame(model.cv_results_)\n",
    "df_result.to_csv()\n",
    "# fit and predict\n",
    "y_train_hat = model.predict(X_train_std)\n",
    "y_test_hat = model.predict(X_test_std)\n",
    "# plot\n",
    "fontsize = 12\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.style.use('default')\n",
    "plt.rc('xtick', labelsize=fontsize)\n",
    "plt.rc('ytick', labelsize=fontsize)\n",
    "plt.rcParams['font.family'] = \"Arial\"\n",
    "a = plt.scatter(y_train, y_train_hat, s=25, c='#b2df8a')\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k:', lw=1.5)\n",
    "plt.xlabel('Observation', fontsize=fontsize)\n",
    "plt.ylabel('Prediction', fontsize=fontsize)\n",
    "plt.tick_params(direction='in')\n",
    "plt.title(('Train RMSE: {:.2e}'.format(np.sqrt(metrics.mean_squared_error(y_train, y_train_hat))),\n",
    "           'Test RMSE: {:.2e}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_test_hat)))), fontsize=fontsize)\n",
    "b = plt.scatter(y_test, y_test_hat, s=25, c='#1f78b4')\n",
    "plt.legend((a, b), ('Train', 'Test'), fontsize=fontsize, handletextpad=0.1, borderpad=0.1)\n",
    "plt.rcParams['font.family'] = \"Arial\"\n",
    "plt.tight_layout()\n",
    "savefig(\"xgb.jpg\", bbox_inches='tight')\n",
    "np.savetxt('xgb_y_test.csv', y_test_hat, delimiter=',')\n",
    "np.savetxt('xgb_y_train.csv', y_train_hat, delimiter=',')\n",
    "np.savetxt('xgb_x_test.csv', y_test, delimiter=',')\n",
    "np.savetxt('xgb_x_train.csv', y_train, delimiter=',')\n",
    "plt.show()\n",
    "print('r:', stats.pearsonr(y_train, y_train_hat))\n",
    "print('r:', stats.pearsonr(y_test, y_test_hat))\n",
    "print('XGBåœ¨è®­ç»ƒé›†çš„r:', stats.pearsonr(y_train, y_train_hat))\n",
    "print('XGBåœ¨æµ‹è¯•é›†çš„r:', stats.pearsonr(y_test, y_test_hat))\n",
    "print('XGBåœ¨è®­ç»ƒé›†çš„å†³å®šç³»æ•°R2: %.3f' % (r2_score(y_train, y_train_hat)))  # è®¡ç®—å‡æ–¹è¯¯å·®å›å½’æŸå¤±ï¼Œè¶Šæ¥è¿‘äº1æ‹Ÿåˆæ•ˆæœè¶Šå¥½å†³å®šç³»æ•°Rå¹³æ–¹\n",
    "print('XGBåœ¨è®­ç»ƒé›†çš„å‡æ–¹æ ¹è¯¯å·®RMSE: %.3f' % (np.sqrt(mean_squared_error(y_train, y_train_hat))))  # è®¡ç®—å‡æ–¹å·®æ ¹åˆ¤æ–­æ•ˆæœRMSEï¼ˆRoot Mean Squared Errorï¼‰\n",
    "print('XGBåœ¨è®­ç»ƒé›†çš„å¹³å‡ç»å¯¹è¯¯å·®MAE: %.3f' % (mean_absolute_error(y_train, y_train_hat)))  # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·® MAE\n",
    "print('XGBåœ¨è®­ç»ƒé›†çš„å¹³å‡ç»å¯¹ç™¾åˆ†è¯¯å·®MAPE: %.3f' % (mean_absolute_percentage_error(y_train, y_train_hat)))  # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·® MAPE\n",
    "print('XGBåœ¨æµ‹è¯•é›†çš„å†³å®šç³»æ•°R2: %.3f' % (r2_score(y_test, y_test_hat)))  # è®¡ç®—å‡æ–¹è¯¯å·®å›å½’æŸå¤±ï¼Œè¶Šæ¥è¿‘äº1æ‹Ÿåˆæ•ˆæœè¶Šå¥½å†³å®šç³»æ•°Rå¹³æ–¹\n",
    "print('XGBåœ¨æµ‹è¯•é›†å‡æ–¹æ ¹è¯¯å·®RMSE: %.3f' % (np.sqrt(mean_squared_error(y_test, y_test_hat))))  # è®¡ç®—å‡æ–¹å·®æ ¹åˆ¤æ–­æ•ˆæœRMSEï¼ˆRoot Mean Squared Errorï¼‰\n",
    "print('XGBåœ¨æµ‹è¯•é›†çš„å¹³å‡ç»å¯¹è¯¯å·®MAE: %.3f' % (mean_absolute_error(y_test, y_test_hat)))  # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·® MAE\n",
    "print('XGBåœ¨æµ‹è¯•é›†çš„å¹³å‡ç»å¯¹ç™¾åˆ†è¯¯å·®MAPE: %.3f' % (mean_absolute_percentage_error(y_test, y_test_hat)))  # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·® MAPE\n",
    "print('å‚æ•°çš„æœ€ä½³å–å€¼ï¼š{0}'.format(model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "963cc523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾æ•°: 31\n",
      "ğŸš€ å¼€å§‹é¢„æµ‹...\n",
      "âœ… è¾“å…¥æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå½¢çŠ¶: (1, 31)\n",
      "âœ… æ ‡å‡†åŒ–å®Œæˆ\n",
      "âœ… é¢„æµ‹å®Œæˆï¼Œç»“æœ: [28.7449]\n",
      "Predicted Adsorption Capacity: 28.7449 mg/g\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# è¯»å–ç”¨æˆ·ä¸Šä¼ çš„åŸå§‹æ•°æ®æ–‡ä»¶\n",
    "file_path = \"./sample.csv\"\n",
    "data = pd.read_csv(file_path, encoding=\"gbk\")\n",
    "\n",
    "# è·å–ç‰¹å¾æ•°\n",
    "num_features = data.shape[1] - 1  # ç›®æ ‡å˜é‡ 'Adsorption capacity' ä¸è®¡å…¥ç‰¹å¾æ•°\n",
    "print(f\"ç‰¹å¾æ•°: {num_features}\")\n",
    "\n",
    "# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡\n",
    "X = data.drop(columns=['Adsorption capacity'])\n",
    "y = data['Adsorption capacity']\n",
    "\n",
    "# æ•°æ®æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# è®­ç»ƒXGBoostæ¨¡å‹\n",
    "best_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 3,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 3\n",
    "}\n",
    "\n",
    "xgb_regressor = xgb.XGBRegressor(**best_params)\n",
    "xgb_regressor.fit(X_std, y)\n",
    "\n",
    "# æå–æ‰€æœ‰ \"Substrate_\", \"Heavy metal ions_\", å’Œ \"Modified\" ç›¸å…³çš„åˆ—\n",
    "substrate_columns = [col for col in data.columns if col.startswith(\"Substrate_\")]\n",
    "heavy_metal_columns = [col for col in data.columns if col.startswith(\"Heavy metal ions_\")]\n",
    "modified_columns = [col for col in data.columns if col.startswith(\"Modified\")]\n",
    "\n",
    "# åˆ›å»ºåŒ…å«æ‰€æœ‰æƒ…å†µçš„é»˜è®¤è¾“å…¥å€¼å­—å…¸ï¼ˆé»˜è®¤è®¾ä¸º0ï¼‰\n",
    "default_feature_values = {col: 0 for col in substrate_columns + heavy_metal_columns + modified_columns}\n",
    "\n",
    "# åˆ›å»ºä¸æ¨¡å‹è¾“å…¥æ ¼å¼åŒ¹é…çš„ DataFrameï¼ˆX_inputï¼‰\n",
    "def create_input_dataframe(feature_values):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºè¾“å…¥æ•°æ®æ¡†ï¼Œä¿è¯ä¸æ¨¡å‹è®­ç»ƒæ—¶çš„ç‰¹å¾åŒ¹é…\n",
    "    :param feature_values: å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰ç‰¹å¾åç§°åŠå…¶å¯¹åº”çš„å€¼\n",
    "    :return: DataFrame æ ¼å¼çš„è¾“å…¥æ•°æ®\n",
    "    \"\"\"\n",
    "    X_input = pd.DataFrame([feature_values])\n",
    "    return X_input\n",
    "\n",
    "def predict_external_data(external_data):\n",
    "    print(\"ğŸš€ å¼€å§‹é¢„æµ‹...\")\n",
    "    \n",
    "    # é‡æ–°æ’åºï¼Œä½¿å…¶ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´\n",
    "    external_data = external_data.reindex(columns=scaler.feature_names_in_, fill_value=0)\n",
    "    \n",
    "    print(\"âœ… è¾“å…¥æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå½¢çŠ¶:\", external_data.shape)\n",
    "\n",
    "    # å°è¯•æ ‡å‡†åŒ–æ•°æ®\n",
    "    try:\n",
    "        external_data_std = scaler.transform(external_data)\n",
    "        print(\"âœ… æ ‡å‡†åŒ–å®Œæˆ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Scaler transform å‡ºé”™: {e}\")\n",
    "        return None  # è¿”å› None é¿å…åç»­é”™è¯¯\n",
    "\n",
    "    # å°è¯•è¿›è¡Œé¢„æµ‹\n",
    "    try:\n",
    "        predictions = xgb_regressor.predict(external_data_std)\n",
    "        print(\"âœ… é¢„æµ‹å®Œæˆï¼Œç»“æœ:\", predictions)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ XGBoost é¢„æµ‹å‡ºé”™: {e}\")\n",
    "        return None  # è¿”å› None é¿å…åç»­é”™è¯¯\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "# ç¤ºä¾‹ï¼š\n",
    "# å®šä¹‰ä¸€ä¸ªæ ·æœ¬çš„ç‰¹å¾å€¼ï¼ˆç”¨æˆ·éœ€è¦æä¾›å®é™…å€¼ï¼‰\n",
    "feature_values = {\n",
    "    'Specific surface area': 100.0,\n",
    "    'Pore volume': 0.2,\n",
    "    'Average pore': 5.0,\n",
    "    'Dosage': 0.5,\n",
    "    'Initial concentration': 10.0,\n",
    "    'Temperature': 25,\n",
    "    'Contact time': 30,\n",
    "    'pH': 6.0,\n",
    "    'Substrate_Fe-Mn binary compound': 0,\n",
    "    'Substrate_MnO2': 1,\n",
    "    'Substrate_MnOx': 0,\n",
    "    'Heavy metal ions_As(â…¢)': 0,\n",
    "    'Heavy metal ions_As(â…¤)': 0,\n",
    "    'Heavy metal ions_Cd(â…¡)': 0,\n",
    "    'Heavy metal ions_Co(â…¡)': 0,\n",
    "    'Heavy metal ions_Cr(â…¢)': 0,\n",
    "    'Heavy metal ions_Cr(â…¥)': 1,\n",
    "    'Heavy metal ions_Cu(â…¡)': 0,\n",
    "    'Heavy metal ions_Fe(â…¡)': 0,\n",
    "    'Heavy metal ions_Hg(â…¡)': 0,\n",
    "    'Heavy metal ions_Mn(â…¡)': 0,\n",
    "    'Heavy metal ions_Ni(â…¡)': 0,\n",
    "    'Heavy metal ions_Pb(â…¡)': 0,\n",
    "    'Heavy metal ions_Sb(â…¢)': 0,\n",
    "    'Heavy metal ions_Sb(â…¤)': 0,\n",
    "    'Heavy metal ions_Zn(â…¡)': 0,\n",
    "    'Modified_Chemical modification': 0,\n",
    "    'Modified_Composite modification': 0,\n",
    "    'Modified_Magnetic properties': 0,\n",
    "    'Modified_Nano modification': 0,\n",
    "    'Modified_Others': 1\n",
    "}\n",
    "\n",
    "# åˆ›å»ºè¾“å…¥æ•°æ®\n",
    "X_input = create_input_dataframe(feature_values)\n",
    "\n",
    "# è°ƒç”¨é¢„æµ‹å‡½æ•°\n",
    "y_pred = predict_external_data(X_input)\n",
    "\n",
    "# åªæœ‰ y_pred ä¸æ˜¯ None æ—¶æ‰æ‰“å°\n",
    "if y_pred is not None:\n",
    "    print(f\"Predicted Adsorption Capacity: {y_pred[0]:.4f} mg/g\")\n",
    "else:\n",
    "    print(\"âŒ é¢„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ï¼\")\n",
    "\n",
    "\n",
    "\n",
    "# è¾“å‡ºé¢„æµ‹ç»“æœ\n",
    "#print(f\"Predicted Adsorption Capacity: {y_pred[0]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotelearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}